Excercise: 5
1.f-  Preset

kubectl get pods
kubectl get podpreset
nano pod-preset.yaml

apiVersion: settings.k8s.io/v1alpha1
kind: PodPreset
metadata:
  name: allow-database
spec:
  selector:
    matchLabels:
      role: frontend
  env:
    - name: DB_PORT
      value: "6379"
  volumeMounts:
    - mountPath: /cache
      name: cache-volume
  volumes:
    - name: cache-volume
      emptyDir: {}

kubectl create -f pod-preset.yaml

kubectl get podpreset

nano website.yaml

apiVersion: v1
kind: Pod
metadata:
  name: website
  labels:
    app: website
    role: frontend
spec:
  containers:
    - name: website
      image: nginx
      ports:
        - containerPort: 80

kubectl create -f website.yaml
kubectl get pods
kubectl describe pod website

=========================

Exercise: 6
Task: Resources > Memory
Link: https://networkandcode.blog/2019/03/28/kubernetes-pods-containers-resources-memory/

=============================

Exercise: 7
Task: Resources > CPU
Link: https://networkandcode.blog/2019/03/28/kubernetes-pods-containers-resources-cpu/

=============================

https://networkandcode.blog/2019/03/28/kubernetes-pods-volumes-empty-dir/

==================================

excercise 16 to be checked again
8.b- persistent volume

mkdir /mnt/data
echo 'Hello from Kubernetes storage' > /mnt/data/index.html

nano task-pv-volume.yaml

kind: PersistentVolume
apiVersion: v1
metadata:
  name: task-pv-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/data"

kubectl create -f task-pv-volume.yaml
kubectl get pv task-pv-volume

nano task-pv-claim.yaml

kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: task-pv-claim
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3Gi

kubectl create -f task-pv-claim

kubectl get pv task-pv-volume
kubectl get pvc task-pv-claim

nano task-pv-pod.yaml

kind: Pod
apiVersion: v1
metadata:
  name: task-pv-pod
spec:
  volumes:
    - name: task-pv-storage
      persistentVolumeClaim:
       claimName: task-pv-claim
  containers:
    - name: task-pv-container
      image: nginx
      ports:
        - containerPort: 80
          name: "http-server"
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: task-pv-storage

kubectl create -f task-pv-pod.yaml

kubectl exec -it task-pv-pod -- /bin/bash
apt-get update
apt-get install curl
curl localhost
=====================================

ex17 tbc

8.d- configmap
	
nano configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: special-config
  namespace: default
data:
  special.level: very
  special.type: charm

nano config-pod.yaml

apiVersion: v1
kind: Pod
metadata:
  name: dapi-test-pod
spec:
  containers:
    - name: test-container
      image: k8s.gcr.io/busybox
      command: [ "/bin/sh", "-c", "env" ]
      envFrom:
      - configMapRef:
          name: special-config
  restartPolicy: Never


kubectl get pods
kubectl exec -it podname -- /bin/bash
"ls /etc/config/"

============================

11.b- Share information using files

kubectl get pods

nano dapi-volume.yaml

apiVersion: v1
kind: Pod
metadata:
  name: kubernetes-downwardapi-volume-example
  labels:
    zone: us-est-coast
    cluster: test-cluster1
    rack: rack-22
  annotations:
    build: two
    builder: john-doe
spec:
  containers:
    - name: client-container
      image: k8s.gcr.io/busybox
      command: ["sh", "-c"]
      args:
      - while true; do
          if [[ -e /etc/podinfo/labels ]]; then
            echo -en '\n\n'; cat /etc/podinfo/labels; fi;
          if [[ -e /etc/podinfo/annotations ]]; then
            echo -en '\n\n'; cat /etc/podinfo/annotations; fi;
          sleep 5;
        done;
      volumeMounts:
        - name: podinfo
          mountPath: /etc/podinfo
          readOnly: false
  volumes:
    - name: podinfo
      downwardAPI:
        items:
          - path: "labels"
            fieldRef:
              fieldPath: metadata.labels
          - path: "annotations"
            fieldRef:
              fieldPath: metadata.annotations

kubectl create -f dapi-volume.yaml
kubectl get pods
kubectl logs kubernetes-downwardapi-volume-example
kubectl exec -it kubernetes-downwardapi-volume-example -- sh
cat /etc/podinfo/labels
cat /etc/podinfo/annotations
ls -laR /etc/podinfo
exit


12.c- Loadbalancer

kubectl get pods
kubectl run hello-world --replicas=2 --labels="run=load-balancer-example" --image=gcr.io/google-samples/node-hello:1.0  --port=8080
kubectl get pods
kubectl expose deployment <your-deployment> --type="LoadBalancer" --name="example-service"
kubectl get services
kubectl get services example-service --watch
curl <your-external-ip-address>:8080
===================================

12.d-  kubectl port-forward

kubectl get pods
kubectl create -f https://k8s.io/docs/tasks/access-application-cluster/redis-master.yaml
kubectl get pods
kubectl get pods redis-master --template='{{(index (index .spec.containers 0).ports 0).containerPort}}{{"\n"}}'
kubectl port-forward redis-master 6379:6379
redis-cli
127.0.0.1:6379>ping

============================================
M3D4- Scheduling pods using taints

kubectl get nodes
kubectl taint nodes (nodename) env=dev:NoSchedule
kubectl run nginx —image=nginx
kubectl label deployments/nginx env=dev
kubectl scale deployments/nginx —replicas=5
kubectl get pods -o wide
============================================
m3D5- Tolerations

kubectl get nodes
kubectl taint nodes (nodename) env=dev:NoSchedule
kubectl describe nodes (nodename)
nano dep.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 7
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
      tolerations:
      - key: “dev”
        operator: “Equal”
        value: “env”
        effect: “NoSchedule”
    

    

kubectl get pods -o wide

M3D16- Volumes Demo

gcloud compute disks list
nano volume-sample.yaml

apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: k8s.gcr.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /test-pd
      name: test-volume
  volumes:
  - name: test-volume
    gcePersistentDisk: (diskname)
      pdName:
      fsType: ext4

kubectl create -f vlume-sample.yaml
kubectl describe po test-pd

========================================
 M4d4- Stateful Sets deployment order Demo

nano Sts.yaml

apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: web
  clusterIP: None
  selector:
    app: nginx
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  serviceName: "nginx"
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: k8s.gcr.io/nginx-slim:0.8
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
  volumeClaimTemplates:
  - metadata:
      name: www
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi

kubectl apply -f Sts.yaml
kubectl get pods -w -l app=nginx
kubectl scale Sts web —replicas=4
kubectl get pods -w -l app=nginx

=======================================
Accessing secrets Demo

kubectl get secrets
kubectl describe secrets/sensitive
kano secret-pod.yaml

apiVersion: v1
kind: Pod
metadata
  name: secret-pod

