---
layout: post
title: Kubernetes > Software components
date: 
type: post
parent_id: '0'
published: false
password: ''
status: draft
categories: []
tags: []
meta: {}
author:
  login: shak1r
  email: shakir@techie.com
  display_name: shakir
  first_name: ''
  last_name: ''
permalink: "/"
---
<p>A Kubernetes system is said to be distributed because the software might not be installed in just one machine, it could be installed in a collective group of machines serving the whole purpose of a single Kubernetes system. A Kubernetes cluster is a group of nodes(VMs / Physical servers) on which the different components of the overall Kubernetes software are installed. However using VMs as nodes is quite common and popular these days. There are two types of nodes - Masters and Workers(Workers are just called as nodes often). There could be one or more Master in the Cluster, when there are more than one master, we call it a High Available (HA) Cluster. The master nodes are collectively referred to as the control plane, as the master nodes control the worker nodes. Note that it's also possible to install all the master and worker software components onto a single node, which is often referred to as an all in one (AIO) installation, however it's primarily used in learning environments and not recommended for production systems.</p>
<p>The main software components that are installed on the master are - kube-apiserver, etcd, kube-scheduler, kube-controller-manager, cloud-controller-manager. And those on the worker nodes are kubelet, kube-proxy, container runtime.</p>
<p>kube-apiserver is a REST API server, It is the central software component through which other components of the Master communicate, and it is also used for interconnecting the Kubernetes software components of the Masters and Workers. Any client application or program such as kubectl or some custom code written in any programming language such as python  or some familiar programs such as postman should send an HTTP REST API call to the kube-apiserver to retrieve details of the Kubernetes cluster or to modify it's operation. Note that REST refers to a standard and HTTP is a popular RESTful protocol as it conforms to the compliances of REST.</p>
<p>etcd is a key-value based data store that is proven to be consistent, when we have more than one master with etcd installed on each, we call the group of etcd components as a high available etcd cluster as etcd by itself is a distributed system and it is leveraged for use with Kubernetes. The etcd components in each master interact with each other. etcd is a separate open source software that can also be used with any other software, not just Kubernetes, it is not a native Kubernetes software component and hence we don't see the word kube on it's name. Key value pairs are like dictionaries or maps used with programming languages. Note that key-value pairs are nothing but a collection of keys to which are like variables and each key holding a value, and the value could be a number, string(text), list(array), or even another dictionary(map) and so on. Since etcd stores all the Kubernetes cluster configuration items, it is necessary to have a backup place in plan for the data stored in the etcd cluster. Since etcd by itself is a separate piece of software, all the etcd components in each of the master would interact with each other directly. Note that In a HA cluster, if there are etcd components in more than one master, these don't have to interact with each other through the kube-apiserver like other components, they would interact directly as they are separate from the native Kubernetes processes, however when etcd wants to talk with other native Kubernetes components, it goes through the kube-apiserver.</p>
<p>kube-scheduler is responsible for scheduling or spawning pods on nodes. Pods are the fundamental objects in Kubernetes. Pods would wrap one or more containers inside them as well other associated objects such as volumes that the containers can share. However it's most common to see Pods with single containers. When a Pod is being created, the kube-scheduler is responsible for scheduling it in one of the nodes according to the policies in any as mentioned in the Pod configuration or manifest.</p>
<p>kube-controller-manager is a process that is responsible for running Controller processes such as Node Controller, Replication Controller, Endpoints Controller, Service Account &amp; Token Controllers. Node Controller notifies and responds to node down events. Replication Controller helps maintaining the correct number of replicas(Pods) for the Replica Controller Objects. Endpoints Controller handles service endpoints. A service would have endpoints which refer to the associated Pods and their respective ports. Service Account &amp; Token Controllers deal with service accounts, tokens for new namespaces to allow api access etc.</p>
<p>cloud-controller-manager is a process that is responsible for running processes that interact with the underlying cloud provider, for example, the Google Kubernetes Engine. These processes include Node Controller, Route Controller, Service Controller, and Volume Controller. Each interacting with specific attributes on the Cloud Provider, for example the Route Controller process is responsible for setting up Network Routes in the underlying cloud.</p>
<p>kubelet is the key process in each worker node that ensures that Pods created by Kubernetes are running healthy on the node. Note that kubelet doesn't manager containers that are not created by Kubernetes such as one that's created directly using Docker pull.</p>
<p>kube-proxy is a network daemon that helps the functioning of Kubernetes Service objects. It is responsible for orchestrating service VIP(virtual IP) management on the worker node where it's installed. Services are Kubernetes objects and each Service is assigned a Virtual IP.</p>
<p>A container runtime process such as Docker, Container-D, frakti, rkt(often as rocket) required on each of the worker nodes so that containers be created. Kubelet interacts with the container runtime to ensure containers specified in the Pod spec are created properly. Kubernetes by itself doesn't create containers, it depends on the container run time, hence this container run time is also an external software and not a native Kubernetes process.</p>
<p>In addition to these components, so many add-ons could be enabled in the Kubernetes cluster by creating additional Pods / Services in the kube-system namespace for those respective add-ons. Examples are cluster DNS (this one is essential), Web UI / Dashboard (for a graphical analysis to the cluster and it's objects), container resource monitoring, cluster level logging and so on.</p>
<p>--end-of-post--</p>
